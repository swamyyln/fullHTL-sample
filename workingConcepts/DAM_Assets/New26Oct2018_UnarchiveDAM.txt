package com.arche11.core.damWorkflows;

import java.io.File;
import java.io.FileInputStream;
import java.io.FileNotFoundException;
import java.io.FileOutputStream;
import java.io.IOException;
import java.io.InputStream;
import java.io.InputStreamReader;
import java.text.ParseException;
import java.text.SimpleDateFormat;
import java.util.ArrayList;
import java.util.Calendar;
import java.util.Date;
import java.util.HashMap;
import java.util.Iterator;
import java.util.LinkedList;
import java.util.List;
import java.util.Locale;
import java.util.Map;
import java.util.Set;
import java.util.Map.Entry;
import java.util.regex.Matcher;
import java.util.regex.Pattern;
import java.util.zip.ZipEntry;
import java.util.zip.ZipInputStream;
import java.util.zip.ZipOutputStream;

import javax.jcr.Node;
import javax.jcr.PathNotFoundException;
import javax.jcr.RepositoryException;
import javax.jcr.Session;
import javax.jcr.version.Version;

import org.apache.commons.io.IOUtils;
import org.apache.commons.lang.StringUtils;
import org.apache.jackrabbit.util.Text;
import org.apache.sling.api.resource.LoginException;
import org.apache.sling.api.resource.Resource;
import org.apache.sling.api.resource.ResourceResolver;
import org.apache.sling.api.resource.ResourceResolverFactory;
import org.apache.sling.commons.mime.MimeTypeService;
import org.apache.sling.jcr.resource.JcrResourceUtil;
import org.osgi.framework.Constants;
import org.osgi.service.component.annotations.Component;
import org.osgi.service.component.annotations.Reference;
import org.slf4j.Logger;
import org.slf4j.LoggerFactory;
import org.supercsv.cellprocessor.ift.CellProcessor;
import org.supercsv.io.CsvMapReader;
import org.supercsv.io.ICsvMapReader;
import org.supercsv.prefs.CsvPreference;

import com.adobe.granite.workflow.WorkflowException;
import com.adobe.granite.workflow.WorkflowSession;
import com.adobe.granite.workflow.exec.WorkItem;
import com.adobe.granite.workflow.exec.WorkflowData;
import com.adobe.granite.workflow.exec.WorkflowProcess;
import com.adobe.granite.workflow.metadata.MetaDataMap;
import com.arche11.UnarchivalFlow.CustomUnarchiverProcessConfigService;
import com.arche11.UnarchivalFlow.MetadataCSVBean;
import com.day.cq.dam.api.Asset;
import com.day.cq.dam.api.AssetManager;
import com.day.cq.replication.ReplicationActionType;
import com.day.cq.replication.Replicator;
import com.day.cq.tagging.Tag;
import com.day.cq.tagging.TagManager;


@Component(service=WorkflowProcess.class,property={"process.label=myCreateDAMAssetsFromFolder",
        Constants.SERVICE_DESCRIPTION+"=This is my custom DAM assets creation from folder"})
public class CreateDAMAssetsFromFolder implements WorkflowProcess {

	@Reference
	ResourceResolverFactory rrf;
	
	@Reference
	CustomUnarchiverProcessConfigService unarchiveConfigService;
	
	 @Reference
	  private MimeTypeService mimeTypeService;
	 
	 @Reference
	private Replicator replicationService;
	 
	 @Reference
	 NewcreateVersionProcessService newcreateVersionProcessService;

     
    // List<String> errorMsgs=new ArrayList<>();
	
	private ResourceResolver resourceResolver;

	private Session jcrSession;
	
	private AssetManager assetManager = null;

	private TagManager tagManager;
	
	private static final String SHAREPOINT_DAM_FOLDER = "/content/dam/thf/en/docs/auth";
	
	private static final String JCR_CONTENT_NODE = "jcr:content";

	private static final String METADATA_NODE = "metadata";
	
	private static final Logger log=LoggerFactory.getLogger(CreateDAMAssetsFromFolder.class);
	
	private static final String SHAREPOINT_SFTP_FOLDER="C:/Users/YE20004956/Desktop/UNARCHIVER_Process_Test";
	
	private static final String THF_TAGS_PRODUCTS = "/etc/tags/thf/products";
	
	private static final String THF_TAGS_ETF = "/etfs";

	private static final String THF_TAGS_FUNDS = "/funds";
	
	@Override
	public void execute(WorkItem workItem, WorkflowSession wfSession, MetaDataMap meadataMap) throws WorkflowException {
	
		 
			
	    
	      
		final WorkflowData data = workItem.getWorkflowData();
		
		List<MetadataCSVBean> finaliMetadataCsvList=new ArrayList<>();
		
		Matcher dateMatcherMMDDYYYY = null;
		
		Map<String, Object> param = new HashMap<String, Object>();
        param.put(ResourceResolverFactory.SUBSERVICE, "myWorkflowInvokeService");
        
        try {
			ResourceResolver rr=this.rrf.getServiceResourceResolver(param);
			
			if(rr!=null){
				log.info("obtained resource resolver with user name : "+rr.getUserID().toString());
			}
			
			this.tagManager = rr.adaptTo(TagManager.class);
			
			this.assetManager = rr.adaptTo(AssetManager.class);
			
			//1.read csv file
			
			 Map<String,MetadataCSVBean> outputFinalMap=this.readCSVFile(); 
			
	      /*  log.info("After readCSVData");
	        Set<Map.Entry<String,MetadataCSVBean>> entrySet = outputFinalMap.entrySet();
	        
	        // Collection Iterator
	        Iterator<Entry<String,MetadataCSVBean>> iterator = entrySet.iterator();
	 
	        while(iterator.hasNext()) {
	 
	            Entry<String,MetadataCSVBean>> entryList = iterator.next();
	 
	            finaliMetadataCsvList=entryList.getKey();
	            
	        }*/
	        
	       /* for(MetadataCSVBean metadataCSVBeanObj : finaliMetadataCsvList ){
	        	log.info("file name :"+metadataCSVBeanObj.getFile() + " with webId : "+metadataCSVBeanObj.getWebId() +" with Library name : "+metadataCSVBeanObj.getLibrary());
	        }*/
			//2.createDamAssetsFromFolder()
	        
	        try {
				this.createDamAssetsFromFolder(null,outputFinalMap,rr);
			} catch (FileNotFoundException e) {
				// TODO Auto-generated catch block
				e.printStackTrace();
			}
			
		} catch (LoginException e) {
			e.printStackTrace();
		}
	}

	private  Map<String,MetadataCSVBean>  readCSVFile(){
		
		 MetadataCSVBean metadataCSVBeanObj=null;
		 List<Map<String, Object>> csvRowDataList = null;
	      FileInputStream fis = null;
	      Map<String,MetadataCSVBean> finalMap=new HashMap<>();
	      
	      String file=null;
	      String fileName=null;
	      String libraryName=null;
	      String fundName=null;
	      String ticker=null;
	      String webId=null;
	      String subAdvisor=null;
	      String year=null;
	      String quarter=null;
	      String modified=null;
	     
	     
		
		File folder = new File(SHAREPOINT_SFTP_FOLDER);
		for(final File fileEntry:folder.listFiles()){
			
			log.info("file name : "+fileEntry.getName());
			if(fileEntry.getName().endsWith(".csv")){
				 try {
					fis = new FileInputStream(fileEntry);
					
                    InputStreamReader inputStreamReader = new InputStreamReader(fis);
			        
			        csvRowDataList = new ArrayList<Map<String, Object>>();
			        csvRowDataList=this.readCSVRows(inputStreamReader);
			        
			        int i=0;
			        if (null != csvRowDataList && !csvRowDataList.isEmpty()) {
						log.info("csvRowDataList is not empty");
						// Populate funds from csv
						for (final Map<String, Object> rowDataMap : csvRowDataList) {
	                             i++;
							//log.info("Swamy your final map entry :"+ i +"=" + rowDataMap);
	                             metadataCSVBeanObj=new MetadataCSVBean();
	                             if (StringUtils.isNotEmpty((String) rowDataMap
	     								.get("File"))) {
	                            	 file=rowDataMap.get("File").toString();
	                            	 metadataCSVBeanObj.setFile(file);
	     						}
	                             if (StringUtils.isNotEmpty((String) rowDataMap
	     								.get("FileName"))) {
	                            	 fileName=rowDataMap.get("FileName").toString();
	     							metadataCSVBeanObj.setFileName(fileName);
	     						}
	                             if (StringUtils.isNotEmpty((String) rowDataMap
	     								.get("Library"))) {
	                            	 libraryName=rowDataMap.get("Library").toString();
	     							metadataCSVBeanObj.setLibrary(libraryName);
	     						}
	     						
	                             if (StringUtils.isNotEmpty((String) rowDataMap
	     								.get("FundName"))) {
	                            	 fundName=rowDataMap.get("FundName").toString();
	                            	 metadataCSVBeanObj.setFundName(fundName);
	     						}
	                             if (StringUtils.isNotEmpty((String) rowDataMap
	     								.get("Ticker"))) {
	                            	 ticker=rowDataMap.get("Ticker").toString();
	                            	 metadataCSVBeanObj.setTicker(ticker);
	     						}
	                             if (StringUtils.isNotEmpty((String) rowDataMap
	     								.get("WebID"))) {
	                            	 webId=rowDataMap.get("WebID").toString();
	                            	 metadataCSVBeanObj.setWebId(webId);
	     						}
	                             if (StringUtils.isNotEmpty((String) rowDataMap
	     								.get("SubAdvisor"))) {
	                            	 subAdvisor=rowDataMap.get("SubAdvisor").toString();
	                            	 metadataCSVBeanObj.setSubAdvisor(subAdvisor);
	     						}
	                             if (StringUtils.isNotEmpty((String) rowDataMap
	     								.get("Year"))) {
	                            	 year=rowDataMap.get("Year").toString();
	                            	 metadataCSVBeanObj.setYear(year);
	     						}
	                             if (StringUtils.isNotEmpty((String) rowDataMap
	     								.get("Quarter"))) {
	                            	 quarter=rowDataMap.get("Quarter").toString();
	                            	 metadataCSVBeanObj.setQuarter(quarter);
	     						}
							if (StringUtils.isNotEmpty((String) rowDataMap
									.get("Modified"))) {
								modified=rowDataMap.get("Modified").toString();
								metadataCSVBeanObj.setModified(modified);
							}
							//metadataCSVObjList.add(metadataCSVBeanObj);
							
							 finalMap.put(file,metadataCSVBeanObj);
							
							//log.info("metadataCSVObjList : "+metadataCSVObjList);
						}
						
					}
			        
				} catch (FileNotFoundException e) {
					e.printStackTrace();
				}
				 finally
			      {
			        IOUtils.closeQuietly(fis);
			      }
			        
			} else{
	    		  log.info("Not a CSV file");
	    		  //errorMsgs.add("NO CSV file found inside Folder");
	    	  }
	    	  log.info("finalMap : "+finalMap);
		}
		
		return finalMap;
	}
	
	private void createDamAssetsFromFolder(File fldr,Map<String,MetadataCSVBean> csvMetadataBeanMap ,ResourceResolver rr) throws FileNotFoundException, WorkflowException{
	 File folder = new File(SHAREPOINT_SFTP_FOLDER);
	 Map<String,String> libraryDamLocationMap=new HashMap<>();
	 // Map<String,String> documentWebIdMap=new HashMap<>();
	  
	  FileInputStream fis = null;
	  
	  String[] myDamLibArray=unarchiveConfigService.getTHFLibraryDocLocation();
	    
	    for(String myDamLibMapObj:myDamLibArray){
	  	  String[] innerArry=myDamLibMapObj.split("=");
	  	  log.info("After Split key = "+innerArry[0]);
	  	  log.info("After Split value = "+innerArry[1]);
	  	libraryDamLocationMap.put(innerArry[0], innerArry[1]);
	    }
	    
		/*Map<String,String> doclibraryMap=new HashMap<>();
		
		for(MetadataCSVBean metadataCSVObj: csvMetadataBeanList){
			doclibraryMap.put(metadataCSVObj.getFile(), metadataCSVObj.getLibrary());
			documentWebIdMap.put(metadataCSVObj.getFile(), metadataCSVObj.getWebId());
		log.info("List Details ; File :"+metadataCSVObj.getFile() +" and LibraryName :"+metadataCSVObj.getLibrary() +" and tag name : "+metadataCSVObj.getWebId());
		}*/
		
		log.info("csvMetadataBeanMap size : "+csvMetadataBeanMap.size());
	 
	for(final File fileEntry:folder.listFiles()){
		log.info("file entry name : [{}] ",fileEntry.getName());
		 try {
		if(fileEntry.isDirectory()){
			log.info("file entry is directory with path : [{}] ",fileEntry.getName());
		}else{
			//eliminate csv file upload
			if(!fileEntry.getName().endsWith(".csv")){
			String fileEntryfileName=fileEntry.getName();
			
			log.info("1. file name = "+ fileEntryfileName);
			log.info("2. corresponding library name = "+ csvMetadataBeanMap.get(fileEntryfileName).getLibrary());
			log.info("3. corresponding dam location = "+ libraryDamLocationMap.get(csvMetadataBeanMap.get(fileEntryfileName).getLibrary()));
			log.info("For file name = "+ fileEntryfileName +" libraryDamLocationMap.get(csvMetadataBeanMap.get(fileEntryfileName).getLibrary()) : "+ libraryDamLocationMap.get(csvMetadataBeanMap.get(fileEntryfileName).getLibrary()));
			
			String fullPathWithFileName = libraryDamLocationMap.get(csvMetadataBeanMap.get(fileEntryfileName).getLibrary())+"/"+fileEntryfileName;
			
			 Resource resource = rr.getResource(fullPathWithFileName);
	          Asset targetAsset = null;
			 if ((null != resource) && (null != (targetAsset = (Asset)resource.adaptTo(Asset.class))))
	          {
	            log.info("Resource already exists..!!!");
	          }
			   fis = new FileInputStream(fileEntry);
	          String mimeType = this.mimeTypeService.getMimeType(fileEntryfileName);
	          
	          if (null != targetAsset)
	          {
	            Asset newAsset = targetAsset.addRendition("original", fis, mimeType).getAsset();
	      
	            	 log.info("Inside create version loop");
	            	  //this.assetManager.createRevision(targetAsset, "myCustomLabel - "+5, "myComments - "+5);
	          
	            this.updateDocumentMetadata(targetAsset, csvMetadataBeanMap, fileEntryfileName, rr);
	            
	            final Node uploadedAssetNode = targetAsset.adaptTo(Node.class);
	            
	            this.replicationService.replicate(uploadedAssetNode.getSession(),ReplicationActionType.ACTIVATE,uploadedAssetNode.getPath());
	            
	            newcreateVersionProcessService.createCustomVersionService(uploadedAssetNode.getPath());
	            
	            log.info("updated existing asset [{}] from entry [{}]", newAsset.getPath(),fileEntryfileName);
	          }
	          else
	          {
	        	    Asset newAsset = this.getAssetManager().createAsset(fullPathWithFileName, fis, mimeType, true);
	                if (null != newAsset)
	                {
	                	 
	                	 final Node uploadedAssetNode = newAsset.adaptTo(Node.class);
	                	 this.updateDocumentMetadata(newAsset, csvMetadataBeanMap, fileEntryfileName, rr);
	                	 
	                	 log.info("Uploaded asset node path before publishing path : "+uploadedAssetNode.getPath() +"with session :"+uploadedAssetNode.getSession().getUserID());
	                	 this.replicationService.replicate(uploadedAssetNode.getSession(),ReplicationActionType.ACTIVATE,uploadedAssetNode.getPath());
	                	
	                  log.info("extractEntry: created new asset [{}] from entry [{}]", newAsset.getPath(), fileEntryfileName);
	                }
	                else
	                {
	                  log.error("extractEntry: asset manager couldn't create asset for entry [{}]", fileEntryfileName);
	                  throw new WorkflowException("Asset manager couldn't create asset for entry " + fileEntryfileName);
	                }
	          }
			}else{
				log.info("Since it is CSV file no DAM upload required");
			}
			
			
		}
		 }catch(Exception e){
			 log.info("***** exception "+e.getMessage() +e.getCause());
			 e.printStackTrace();
			
		 } finally
	      {
		        IOUtils.closeQuietly(fis);
		   }
	}
	}
	
	
	
	public List<Map<String, Object>> readCSVRows(InputStreamReader reader) {

		List<Map<String, Object>> csvRowsList = new ArrayList<Map<String, Object>>();
		ICsvMapReader mapReader = null;
		try {
			mapReader = new CsvMapReader(reader,
					CsvPreference.STANDARD_PREFERENCE);

			// the header columns are used as the keys to the Map
			final String[] header = mapReader.getHeader(true);
			log.info("readCSVRows after processing cell");
			Map<String, Object> rowMetaDataMap;
			CellProcessor[] migrationProcessor = getMigrationProcessor(header.length);
			while ((rowMetaDataMap = mapReader.read(header, migrationProcessor)) != null) {

				csvRowsList.add(rowMetaDataMap);
			}
		} catch (Exception exception) {
			log.info("readCSVRows Exception occurred : "+ exception);
		} finally {
			if (mapReader != null) {
				try {
					mapReader.close();
					reader.close();
				} catch (IOException ioException) {
					log.info("readCSVRows Exception occurred : "+ ioException);
				}
			}
		}
		return csvRowsList;
	}
	
	private static CellProcessor[] getMigrationProcessor(int colCount) {

		final CellProcessor[] migrationProcessors = new CellProcessor[colCount];
		for (int i = 0; i < migrationProcessors.length; i++) {
			migrationProcessors[i] = null;
		}
		return migrationProcessors;
	}

	 public static  boolean checkForCSVFile(String fileName)
	  {
	      if (null!=fileName && fileName.length()>0 && fileName.contains(".csv")) {
	        return true;
	      }
	    
	    return false;
	  }

	 
	 public AssetManager getAssetManager()
	    {
	      return this.assetManager;
	    }
	 
	 public TagManager getTagManager()
	    {
	      return this.tagManager;
	    }
	 
	 
	 private  boolean updateDocumentMetadata(Asset newAsset,Map<String,MetadataCSVBean> csvMetadataBeanMap,String fileEntryfileName,ResourceResolver rr){
			log.info("Inside updateDocumentMetadata method");
			
		 boolean isMetadataUpdated=false;
	     final String DDMMYYYY_FORMAT = "dd-MM-yyyy HH:mm";
	     
		 Tag resolvedTag = null;
		
		 final Calendar dateCalanderValue = Calendar.getInstance();
		 SimpleDateFormat sdfDDMMYYYY =  new SimpleDateFormat(DDMMYYYY_FORMAT);
		 
		 String[] multiWebIdStr=null;
		 final List<String> tagsList=new ArrayList<>();
		 TagManager tagManager=this.getTagManager();
		 
		 String webIdStr=csvMetadataBeanMap.get(fileEntryfileName).getWebId();
		 log.info("webIdStr : "+webIdStr);
		 if(StringUtils.isNotEmpty(webIdStr)){
			 if(webIdStr.contains(";")){
			 multiWebIdStr=webIdStr.split( ";");
			 for(String tag:multiWebIdStr){
				 log.info(tag);
				 resolvedTag=tagManager.resolve(THF_TAGS_PRODUCTS+THF_TAGS_ETF+"/"+tag.toLowerCase());
				 
				 if (null != resolvedTag) {
					log.info("resolved tag path : "+resolvedTag.getTagID());
						tagsList.add(resolvedTag.getTagID());
					}
				 else{
					 resolvedTag=tagManager.resolve(THF_TAGS_PRODUCTS+THF_TAGS_FUNDS+"/"+tag.toLowerCase());
					 if(null!=resolvedTag){
						 log.info("resolved tag path : "+resolvedTag.getTagID());
						 tagsList.add(resolvedTag.getTagID());
					 }
				 }
			 }
			 }else{
				 log.info("Inside else for file name :" +fileEntryfileName);
				 log.info("tag resolution path :"+THF_TAGS_PRODUCTS+THF_TAGS_ETF+"/"+csvMetadataBeanMap.get(fileEntryfileName).getWebId().toLowerCase());
				 resolvedTag=tagManager.resolve(THF_TAGS_PRODUCTS+THF_TAGS_ETF+"/"+csvMetadataBeanMap.get(fileEntryfileName).getWebId().toLowerCase());
				 log.info("resolved tag name :"+resolvedTag.getPath());
				 if (null != resolvedTag) {
					log.info("resolved tag path : "+resolvedTag.getTagID());
						tagsList.add(resolvedTag.getTagID());
					}
			 
			 }
			 
		
		
		   final Node newAssetNode = newAsset.adaptTo(Node.class);
		
		try {
			if (null != newAssetNode && newAssetNode.hasNode(JCR_CONTENT_NODE+ "/"+ METADATA_NODE)) {
				Node newAssetMetaDataNode = newAssetNode.getNode(JCR_CONTENT_NODE+ "/"+ METADATA_NODE);
				
				//1.Set the document tags
				if (!tagsList.isEmpty()) { 									 	
					log.info("Setting cq:tags [{}] to cq:tags", tagsList);
			   this.setProperty(newAssetMetaDataNode, "cq:tags",tagsList.toArray(), true);
								   isMetadataUpdated=true;
				}
				
				//2.set the "File"  as metadata property Name
				if(null!=csvMetadataBeanMap.get(fileEntryfileName).getFile() && StringUtils.isNotEmpty(csvMetadataBeanMap.get(fileEntryfileName).getFile())){
					
					log.info("Before setting metadata property name = "+ csvMetadataBeanMap.get(fileEntryfileName).getFile());
					 this.setProperty(newAssetMetaDataNode, "name",csvMetadataBeanMap.get(fileEntryfileName).getFile(), true);
					 
					//3.set the "File" with out extension as metadata Property piececode
					String file=csvMetadataBeanMap.get(fileEntryfileName).getFile();
					if(null!=file && file.contains(".")){
					String pieceCode=file.substring(0, file.lastIndexOf('.'));
					log.info("Before setting metadata property piececode = "+ pieceCode);
					 this.setProperty(newAssetMetaDataNode, "piececode",pieceCode, true);
					}
				
				}
				
				
				//4. dc:title
				
				if(null !=csvMetadataBeanMap.get(fileEntryfileName).getFileName() && StringUtils.isNotEmpty(csvMetadataBeanMap.get(fileEntryfileName).getFileName())){
					 this.setProperty(newAssetMetaDataNode, "dc:title",csvMetadataBeanMap.get(fileEntryfileName).getFileName(), true);
				}
				
				//5.Revision Date
				final String strRevisonDate =csvMetadataBeanMap.get(fileEntryfileName).getModified();
				log.info("for file name : "+csvMetadataBeanMap.get(fileEntryfileName).getFile() +" --> strRevisonDate : "+strRevisonDate );
				Date revisonDate = null;
				// Add Revision Date - prism:revisionDate
				if (StringUtils.isNotEmpty(strRevisonDate)) {
				
						revisonDate = sdfDDMMYYYY.parse(strRevisonDate);
						
						log.info("revisonDate --> {}",revisonDate);
						dateCalanderValue.setTime(revisonDate);
						log.info("dateCalanderValue --> {}",dateCalanderValue.getTime());
						log.info("before setting prism revision date : "+dateCalanderValue.getTimeInMillis() +"System Time in Millis :"+System.currentTimeMillis());

				}
				log.info("Setting value1 [{}]  to property prism:revisionDate",dateCalanderValue);
				this.setProperty(newAssetMetaDataNode,"prism:revisionDate", dateCalanderValue, true);
				
			} 
			else {
					log.info("No Tag was set !!!!!!!");
				}
		} catch (PathNotFoundException e) {
			// TODO Auto-generated catch block
			e.printStackTrace();
		} catch (RepositoryException e) {
			// TODO Auto-generated catch block
			e.printStackTrace();
		} catch (ParseException e) {
			// TODO Auto-generated catch block
			e.printStackTrace();
		}
		
		
	 }
		 return isMetadataUpdated;
	 }
	 
	 
	 
	 public boolean setProperty(final Node node, final String name,
	            final Object value, final boolean autoSave) {
	        try {
	            JcrResourceUtil.setProperty(node, name, value);
	            if (autoSave) {
	                this.save(node.getSession());
	            }
	            return true;
	        } catch (final NullPointerException e) {
	           log.info("Could not set property: {}", e);
	        } catch (final RepositoryException e) {
	        	log.info("Could not set property: {}", e);
	        }
	        return false;
	    }
	 
	 public void save(final Session session) {
	        try {
	            if (session != null && session.hasPendingChanges()) {
	                session.refresh(true);
	                session.save();
	            }
	        } catch (final RepositoryException e) {
	            log.info("Could not save session: ", e);
	        }
	    }
	 
	 ///File Utils
	 public static void zipGenerator(String acrhivalPath, final String sourceDir, boolean moveFile) {
	    	File fileSource = null;
	        try {
	            // create object of FileOutputStream
	            acrhivalPath = acrhivalPath + File.separator;
	            // create File object from source directory
	            fileSource = new File(sourceDir);
	            final FileOutputStream fout = new FileOutputStream(acrhivalPath
	                    + getCurrentDate());
	            // create object of ZipOutputStream from FileOutputStream
	            final ZipOutputStream zout = new ZipOutputStream(fout);
	            addDirectory(zout, fileSource);
	            // close the ZipOutputStream
	            zout.close();
	        } catch (final IOException ioe) {
	            log.info("IOException :" + ioe);
			} finally {
				if (fileSource != null && fileSource.exists()
						&& fileSource.isFile() && moveFile) {
					boolean status = fileSource.delete();
					log.info(
							"File deletion status for file [{}]: {}",
							fileSource.getAbsolutePath(), status);
				} else if (fileSource != null && fileSource.exists()
						&& fileSource.isDirectory() && moveFile) {
					for (File file : fileSource.listFiles()) {
						boolean status = file.delete();
						log.info(
								"File deletion status for file [{}]: {}",
								file.getAbsolutePath(), status);
					}
				}
			}
	    }
	 
	 
	 
	 private static void addDirectory(final ZipOutputStream zout,
	            final File fileSource) {

	        // get sub-folder/files list
	        final File[] files = fileSource.listFiles();

	        for (int i = 0; i < files.length; i++) {
	            // if the file is directory, call the function recursively
	            if (files[i].isDirectory()) {
	                addDirectory(zout, files[i]);
	                continue;
	            }

	            /*
	             * we are here means, its file and not directory, so
	             * add it to the zip file
	             */

	            try {

	                // create byte buffer
	                final byte[] buffer =returnByteArray();

	                // create object of FileInputStream
	                final FileInputStream fin = returnFileInputStream(files[i]);

	                zout.putNextEntry(returnZipEntryObj(files[i]
	                        .getName()));

	                /*
	                 * After creating entry in the zip file, actually
	                 * write the file.
	                 */
	                int length;

	                while ((length = fin.read(buffer)) > 0) {
	                    zout.write(buffer, 0, length);
	                }

	                /*
	                 * After writing the file to ZipOutputStream, use
	                 * void closeEntry() method of ZipOutputStream class to
	                 * close the current entry and position the stream to
	                 * write the next entry.
	                 */

	                zout.closeEntry();

	                // close the InputStream
	                fin.close();

	            } catch (final IOException ioe) {
	                log.info("IOException :" + ioe);
	            }
	        }

	    }
	 
	 
	 private static byte[] returnByteArray() {
	        return new byte[1024];
	    }
	 
	 private static FileInputStream returnFileInputStream(final File file)
	            throws FileNotFoundException {
	        // create byte buffer
	        return new FileInputStream(file);
	    }
	 
	 private static ZipEntry returnZipEntryObj(final String fileName) {
	        // create byte buffer
	        return new ZipEntry(fileName);
	    }

	    private static String getCurrentDate() {
	        return new SimpleDateFormat("yyyy_MM_dd_hhmm'.zip'", Locale.US)
	                .format(new Date());
	    }
}
